https://leetcode.com/problems/word-break-ii/description/?envType=problem-list-v2&envId=trie

class Solution {
    public List<String> wordBreak(String s, List<String> wordDict) {
        Set<String> wordSet = new HashSet<>(wordDict);
        Map<String, List<String>> memo = new HashMap<>();
        return dfs(s, wordSet, memo);
    }

    private List<String> dfs(String s, Set<String> wordSet, Map<String, List<String>> memo) {
        if (memo.containsKey(s)) return memo.get(s);
        
        List<String> res = new ArrayList<>();
        if (s.length() == 0) {
            res.add(""); // Base case for recursion
            return res;
        }

        for (int end = 1; end <= s.length(); end++) {
            String prefix = s.substring(0, end);
            if (wordSet.contains(prefix)) {
                List<String> suffixBreaks = dfs(s.substring(end), wordSet, memo);
                for (String suffix : suffixBreaks) {
                    res.add(prefix + (suffix.isEmpty() ? "" : " " + suffix));
                }
            }
        }

        memo.put(s, res);
        return res;
    }
}

Time Complexity: O(N √ó 2‚Åø) (worst case)
- Let N be the length of the string s.
- In the worst case, the string can be broken into words in an exponential number of ways.
- Every suffix leads to recursive calls, but memoization significantly reduces redundant recomputation.
- Actual performance depends on:
- The density of word matches in the dictionary.
- Depth and branching factor of recursive calls.
- Optimistically: closer to polynomial with good memo hits and constrained dictionary.

üß† Space Complexity: O(N √ó K)
- Memoization map stores results for up to N suffixes, each containing potentially K combinations.
- Recursive call stack can go as deep as N.
- Result list stores all valid segmentations, which adds additional space proportional to total number and length of those sentences.

